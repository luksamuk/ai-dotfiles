# =======================================
# Favorite models
# =======================================
[models.ministral]
model_id = "ministral-3:14b"
num_ctx = 32768
temperature = 0.2
top_k = 40
top_p = 0.9
repeat_penalty = 1.1

[models.qwen3-coder]
model_id = "qwen3-coder:30b"
num_ctx = 32768
temperature = 0.3
top_k = 20
top_p = 0.80
repeat_penalty = 1.05

[models.nemotron]
model_id = "nemotron-3-nano:30b"
num_ctx = 32768
temperature = 0.6
top_p = 0.95
thinking = true

[models.gpt-oss]
model_id = "gpt-oss:20b"
num_ctx = 32768
temperature = 1.0
top_k = 0
top_p = 1.0
thinking = true

[models.pepe]
model_id = "pepe:8b"
num_ctx = 65536
temperature = 1.0
repeat_penalty = 1.1

# ======================================
# Cloud models
# ======================================

[models.glm-5]
model_id = "glm-5:cloud"
num_ctx = 202752
thinking = true

[models."kimi-k2.5"]
model_id = "kimi-k2.5:cloud"
num_ctx = 202144
thinking = true

[models."minimax-m2.5"]
model_id = "minimax-m2.5:cloud"
num_ctx = 202752
thinking = true

[models."qwen3.5"]
model_id = "qwen3.5:cloud"
num_ctx = 262144
thinking = true

[models."qwen3-coder-next"]
model_id = "qwen3-coder-next:cloud"
num_ctx = 262144

# ======================================
# Miscellaneous models
# ======================================

[models.translate]
model_id = "translategemma:4b"
num_ctx = 0
temperature = 0.2
top_k = 40
top_p = 0.9
repeat_penalty = 1.1

[models.moondream]
model_id = "moondream:1.8b"
num_ctx = 0
temperature = 0.2
top_k = 40
top_p = 0.9
repeat_penalty = 1.1

# ========================================
#  Recommended models by llm-checker
# ========================================

# [models.mistral-small]
# model_id = "mistral-small:24b"
# num_ctx = 32768
# temperature = 0.2
# top_k = 40
# top_p = 0.9
# repeat_penalty = 1.1


# [models."qwen2.5-coder:32b"]
# model_id = "qwen2.5-coder:32b"


# [models.devstral-small-2]
# model_id = "devstral-small-2:24b"
# num_ctx = 32768
# temperature = 0.15
# top_k = 40
# top_p = 0.9
# repeat_penalty = 1.1


# [models."llama3.2"]
# model_id = "llama3.2:3b"


# [models.deepseek-coder-v2]
# model_id = "deepseek-coder-v2:16b"
# num_ctx = 32768
# temperature = 0.15
# top_k = 40
# top_p = 0.85
# repeat_penalty = 1.05
